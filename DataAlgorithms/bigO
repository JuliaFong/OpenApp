BIG O NOTES

Complexity Analysis
As software engineers, our goal is not just to solve problems. 
Rather, our goal is to solve problems efficiently and elegantly.
 Not all solutions are made equal! 
 In this section we'll explore how to analyze the efficiency of 
 algorithms in terms of their speed (time complexity) and memory consumption (space complexity).

Motivation
Let's begin by understanding what method we 
should not use when describing the 
efficiency of our algorithms. Most importantly, 
we'll want to avoid using absolute units of 
time when describing speed. When the software 
engineer exclaims, "My function runs in 0.2 seconds, 
it's so fast!!!", the computer scientist is not impressed. 
Skeptical, the computer scientist asks the following questions:

What computer did you run it on? Maybe the credit belongs to the hardware and not the software. Some hardware architectures will be better for certain operations than others.
Were there other background processes running on the computer that could have effected the runtime? It's hard to control the environment during performance experiments.
Will your code still be performant if we increase the size of the input? For example, sorting 3 numbers is trivial; but how about a million numbers?
The job of the software engineer is to focus on the software detail and not necessarily the hardware it will run on. Because we can't answer points 1 and 2 with total certainty, we'll want to avoid using concrete units like "milliseconds" or "seconds" when describing the efficiency of our algorithms. Instead, we'll opt for a more abstract approach that focuses on point 3. This means that we should focus on how the performance of our algorithm is effected by increasing the size of the input. In other words, how does our performance scale?

Big-O Notation
In Computer Science, we use Big-O notation as a tool for describing the efficiency of algorithms with respect to the size of the input argument. We use mathematical functions in Big-O notation, so there are a few big picture ideas that we'll want to keep in mind:

The function should be defined in terms of the size of the input(s).
A smaller Big-O function is more desirable than a larger one. Intuitively, we want our algorithms to use the minimal amount of time and memory possible.
Big-O describes the worst case scenario, also known as the upper-bound. We prepare our algorithm for the worst-case, because the best-case is a luxury we can't guarantee.
A Big-O function should be simplified to show only it's most dominant mathematical term.
The first 3 points are conceptual, so they are easy to swallow. However, point 4 is typically the biggest source of confusion when learning the notation. Before we apply Big-O to our code, we'll need to first understand the underlying math and simplification process.


Simplifying Math Terms
We want our Big-O notation to describe the performance of our algorithm with respect to the input size and nothing else. Because of this, we should to simplify our Big-O functions using the following rules:

Simplify Products: if the function is a product of many factors, we drop the factors that don't depend on the size of the input.
Simplify Sums: if the function is a sum of many terms, we keep the term with the largest growth rate and drop the other terms.
Well look at these rules in action, but first we'll define a few things t

n is the size of the input
T(f) refers to the unsimplified function
O(f) refers to the Big-O simplified function

Simplifying a Product
If the function consists of a product of many factors, we drop the factors that don't depend on the size of the input, n. The factors that we drop are called constant factors because their size remains consistent as we increase the size of the input. The reasoning behind this simplification is that we make the input large enough, the non-constant factors will overshadow the constant ones.

Simplifying a Sum
If the function consists of a sum of many terms, we only need to show the term that grows the fastest, relative to the size of the input. The reasoning behind this simplification is that if we make the input large enough, the fastest growing term will overshadow the other, smaller terms. To understand which term to keep, you'll need to recall the relative size of our common math terms from the previous section.

As an aside, we'll often omit the multiplication symbol in expressions as a form of shorthand. For example, we'll write O( 5n2 ) in place of O( 5 * n2 ).

Putting it all together
These two rules are all we'll need to Big-O simplify any functions. We just apply the product rule to simplify all terms, then apply the sum rule to select the single most dominant term.


How to Simplify a Function into a Big-O Notation

Simplify Products: if the function is a product of manyu factors, we 
drop the factors that don't depend on the size of the input

Sinplify Sums: if the function is a sum of many terms, we keep
the term with the largest growth rate and drop the other terms

Exercise
It's your turn. Write the Big-O simplified versions of the following functions.


Simplified

T(5n^2) simplified is => O(n^2)

T(1000n) => O(n)

T(42xnxlogn) => O(nlogn)

T(12) => O(1)

Constant, Linear, Logarithmic Complexity




